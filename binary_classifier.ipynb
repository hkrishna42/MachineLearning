{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRAtpGu4IHBg",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "3cb0ba18-8bfb-4398-e77d-51f6dc3b3a57"
      },
      "source": [
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pandas as pd\r\n",
        "import seaborn as sns\r\n",
        "import io\r\n",
        "from google.colab import files\r\n",
        "uploaded = files.upload()\r\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-dff7c7b1-8ed4-44f7-a06c-ba84a637fa05\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-dff7c7b1-8ed4-44f7-a06c-ba84a637fa05\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving data.csv to data.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hp6vdCtTKjWX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a1011bb-4ce6-40b2-d1c0-107012e106d0"
      },
      "source": [
        "df = pd.read_csv(io.BytesIO(uploaded['data.csv']))\r\n",
        "y = df[\"y\"]\r\n",
        "df.drop(\"y\", axis = 1, inplace = True)\r\n",
        "X = df\r\n",
        "print(X)\r\n",
        "print(y)\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import os\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "X_train, temp_X_test, y_train, temp_y_test = train_test_split(X, y, test_size=0.4, random_state=42)\r\n",
        "X_test,X_valid,y_test,y_valid = train_test_split(temp_X_test,temp_y_test,test_size=0.5,random_state=42)\r\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     Unnamed: 0  filename  ...  total_turns  total_distance_travelled\n",
            "0             0  0000.csv  ...            6                   9090.73\n",
            "1             1  0001.csv  ...            9                  10718.68\n",
            "2             2  0002.csv  ...           20                  16852.49\n",
            "3             3  0003.csv  ...            3                   6664.49\n",
            "4             4  0004.csv  ...           18                   2050.49\n",
            "..          ...       ...  ...          ...                       ...\n",
            "995         995  0995.csv  ...           16                   7526.36\n",
            "996         996  0996.csv  ...            9                   9753.48\n",
            "997         997  0997.csv  ...           12                   4342.03\n",
            "998         998  0998.csv  ...           28                   5372.88\n",
            "999         999  0999.csv  ...            9                   6130.62\n",
            "\n",
            "[1000 rows x 19 columns]\n",
            "0      0\n",
            "1      0\n",
            "2      0\n",
            "3      1\n",
            "4      0\n",
            "      ..\n",
            "995    0\n",
            "996    1\n",
            "997    0\n",
            "998    1\n",
            "999    1\n",
            "Name: y, Length: 1000, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWox6LrKNnD9"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Activation, Dense, BatchNormalization, Dropout\r\n",
        "from tensorflow.keras import optimizers"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yWVuJYGOPxV"
      },
      "source": [
        "tf.random.set_seed(13)\r\n",
        "tf.debugging.set_log_device_placement(False)\r\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0SoGMnCeEDS"
      },
      "source": [
        "train_stats = X_train.describe()\r\n",
        "train_stats = train_stats.transpose()\r\n",
        "def norm(x):\r\n",
        "  return (x-train_stats['mean'])/train_stats['std']\r\n",
        "X_train = norm(X_train)\r\n",
        "X_test =norm(X_test)\r\n",
        "\r\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDIlNqjsPrIq",
        "outputId": "3a9918d2-3590-40df-ec51-4bfc7f98de07"
      },
      "source": [
        "def build_model2_three_hidden_layers():\r\n",
        "  model = Sequential()\r\n",
        "  model.add(Dense(32,input_shape = (X_train.shape[1],)))\r\n",
        "  model.add(Dense(32,Activation('relu')))\r\n",
        "  model.add(Dense(64,Activation('relu')))\r\n",
        "  model.add(Dense(128,Activation('relu')))\r\n",
        "  model.add(Dense(1))\r\n",
        "\r\n",
        "  learning_rate= 0.001\r\n",
        "  optimizer = optimizers.SGD(learning_rate)\r\n",
        "  model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),optimizer = optimizer,metrics=['accuracy'])\r\n",
        "  return model\r\n",
        "model2 = build_model2_three_hidden_layers()\r\n",
        "model2.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_9 (Dense)              (None, 32)                480       \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 12,097\n",
            "Trainable params: 12,097\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "h6iKnNx6gx3D",
        "outputId": "00ff973b-e926-46ac-84df-95adf9c47211"
      },
      "source": [
        "X_train.dropna(axis='columns',inplace=True)\r\n",
        "X_train\r\n",
        "X_valid.dropna(axis='columns',inplace=True)\r\n",
        "X_valid\r\n",
        "X_test.dropna(axis='columns',inplace=True)\r\n",
        "X_test\r\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>feature11</th>\n",
              "      <th>feature12</th>\n",
              "      <th>feature13</th>\n",
              "      <th>feature14</th>\n",
              "      <th>feature4</th>\n",
              "      <th>feature5</th>\n",
              "      <th>feature6</th>\n",
              "      <th>feature7</th>\n",
              "      <th>feature8</th>\n",
              "      <th>feature9</th>\n",
              "      <th>total_distance_travelled</th>\n",
              "      <th>total_stops</th>\n",
              "      <th>total_turns</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>526</th>\n",
              "      <td>0.063323</td>\n",
              "      <td>-0.050720</td>\n",
              "      <td>-0.129481</td>\n",
              "      <td>-0.050720</td>\n",
              "      <td>0.064184</td>\n",
              "      <td>0.281288</td>\n",
              "      <td>-1.317486</td>\n",
              "      <td>-1.317486</td>\n",
              "      <td>-1.427031</td>\n",
              "      <td>0.019929</td>\n",
              "      <td>0.030750</td>\n",
              "      <td>-0.019410</td>\n",
              "      <td>0.241383</td>\n",
              "      <td>1.793030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>557</th>\n",
              "      <td>0.170769</td>\n",
              "      <td>-0.050720</td>\n",
              "      <td>-0.129501</td>\n",
              "      <td>-0.050720</td>\n",
              "      <td>-0.528385</td>\n",
              "      <td>0.373676</td>\n",
              "      <td>0.217256</td>\n",
              "      <td>0.217256</td>\n",
              "      <td>-0.818156</td>\n",
              "      <td>-0.609404</td>\n",
              "      <td>0.030750</td>\n",
              "      <td>0.032917</td>\n",
              "      <td>0.054860</td>\n",
              "      <td>4.150140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>290</th>\n",
              "      <td>-0.754648</td>\n",
              "      <td>-0.050714</td>\n",
              "      <td>-0.129487</td>\n",
              "      <td>-0.050714</td>\n",
              "      <td>0.037348</td>\n",
              "      <td>1.287009</td>\n",
              "      <td>-1.046366</td>\n",
              "      <td>-1.046366</td>\n",
              "      <td>-0.222273</td>\n",
              "      <td>0.019929</td>\n",
              "      <td>-0.310919</td>\n",
              "      <td>1.415436</td>\n",
              "      <td>-0.691233</td>\n",
              "      <td>0.573835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141</th>\n",
              "      <td>-1.271079</td>\n",
              "      <td>-0.050720</td>\n",
              "      <td>-0.129450</td>\n",
              "      <td>-0.050720</td>\n",
              "      <td>0.081369</td>\n",
              "      <td>0.480773</td>\n",
              "      <td>-0.504535</td>\n",
              "      <td>-0.504535</td>\n",
              "      <td>-0.553919</td>\n",
              "      <td>0.019929</td>\n",
              "      <td>2.764108</td>\n",
              "      <td>0.762642</td>\n",
              "      <td>-0.285271</td>\n",
              "      <td>-0.645361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>239</th>\n",
              "      <td>-0.931413</td>\n",
              "      <td>-0.050705</td>\n",
              "      <td>-0.129501</td>\n",
              "      <td>-0.050705</td>\n",
              "      <td>-0.013682</td>\n",
              "      <td>0.749756</td>\n",
              "      <td>2.207344</td>\n",
              "      <td>2.207344</td>\n",
              "      <td>0.397233</td>\n",
              "      <td>0.019929</td>\n",
              "      <td>-0.310919</td>\n",
              "      <td>0.137966</td>\n",
              "      <td>0.208467</td>\n",
              "      <td>1.142792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>493</th>\n",
              "      <td>-0.051054</td>\n",
              "      <td>-0.050720</td>\n",
              "      <td>-0.129501</td>\n",
              "      <td>-0.050720</td>\n",
              "      <td>0.606770</td>\n",
              "      <td>1.106913</td>\n",
              "      <td>-1.235621</td>\n",
              "      <td>-1.235621</td>\n",
              "      <td>-1.522856</td>\n",
              "      <td>0.649262</td>\n",
              "      <td>2.764108</td>\n",
              "      <td>0.157397</td>\n",
              "      <td>0.537625</td>\n",
              "      <td>1.224072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>554</th>\n",
              "      <td>0.160371</td>\n",
              "      <td>-0.050716</td>\n",
              "      <td>-0.129499</td>\n",
              "      <td>-0.050716</td>\n",
              "      <td>-1.276562</td>\n",
              "      <td>-1.252904</td>\n",
              "      <td>0.622544</td>\n",
              "      <td>0.622544</td>\n",
              "      <td>1.949346</td>\n",
              "      <td>-1.238737</td>\n",
              "      <td>0.030750</td>\n",
              "      <td>-0.592739</td>\n",
              "      <td>-0.109719</td>\n",
              "      <td>0.492555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>490</th>\n",
              "      <td>-0.061452</td>\n",
              "      <td>-0.050720</td>\n",
              "      <td>-0.129501</td>\n",
              "      <td>-0.050720</td>\n",
              "      <td>0.621503</td>\n",
              "      <td>-0.792576</td>\n",
              "      <td>-0.603263</td>\n",
              "      <td>-0.603263</td>\n",
              "      <td>0.580381</td>\n",
              "      <td>0.649262</td>\n",
              "      <td>0.372420</td>\n",
              "      <td>-0.445984</td>\n",
              "      <td>-0.866784</td>\n",
              "      <td>0.329996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>-1.447844</td>\n",
              "      <td>-0.050451</td>\n",
              "      <td>-0.128914</td>\n",
              "      <td>-0.050451</td>\n",
              "      <td>-0.010912</td>\n",
              "      <td>-0.586635</td>\n",
              "      <td>1.069694</td>\n",
              "      <td>1.069694</td>\n",
              "      <td>1.384029</td>\n",
              "      <td>0.019929</td>\n",
              "      <td>-1.335929</td>\n",
              "      <td>1.293733</td>\n",
              "      <td>-0.427906</td>\n",
              "      <td>-0.889200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>936</th>\n",
              "      <td>1.484375</td>\n",
              "      <td>-0.050720</td>\n",
              "      <td>-0.129501</td>\n",
              "      <td>-0.050720</td>\n",
              "      <td>-1.303773</td>\n",
              "      <td>0.921990</td>\n",
              "      <td>-0.869185</td>\n",
              "      <td>-0.869185</td>\n",
              "      <td>-1.421603</td>\n",
              "      <td>-1.238737</td>\n",
              "      <td>-0.310919</td>\n",
              "      <td>1.542385</td>\n",
              "      <td>-0.724148</td>\n",
              "      <td>-0.645361</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Unnamed: 0  feature11  ...  total_stops  total_turns\n",
              "526    0.063323  -0.050720  ...     0.241383     1.793030\n",
              "557    0.170769  -0.050720  ...     0.054860     4.150140\n",
              "290   -0.754648  -0.050714  ...    -0.691233     0.573835\n",
              "141   -1.271079  -0.050720  ...    -0.285271    -0.645361\n",
              "239   -0.931413  -0.050705  ...     0.208467     1.142792\n",
              "..          ...        ...  ...          ...          ...\n",
              "493   -0.051054  -0.050720  ...     0.537625     1.224072\n",
              "554    0.160371  -0.050716  ...    -0.109719     0.492555\n",
              "490   -0.061452  -0.050720  ...    -0.866784     0.329996\n",
              "90    -1.447844  -0.050451  ...    -0.427906    -0.889200\n",
              "936    1.484375  -0.050720  ...    -0.724148    -0.645361\n",
              "\n",
              "[200 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pb1wedupVhcL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "beb36c59-ebff-437b-af1c-ddc05e1c3469"
      },
      "source": [
        "def build_model1_two_hidden_layers():\r\n",
        "  model = Sequential()\r\n",
        "  model.add(Dense(32,input_shape = (X_train.shape[1],)))\r\n",
        "  #model.add(Dense(32,Activation('relu')))\r\n",
        "  #model.add(Dense(64,Activation('relu')))\r\n",
        "  #model.add(Dense(128,Activation('relu')))\r\n",
        "  model.add(Dense(1))\r\n",
        "\r\n",
        "  learning_rate= 0.0001\r\n",
        "  optimizer = optimizers.SGD(learning_rate)\r\n",
        "  model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),optimizer = optimizer,metrics=['accuracy'])\r\n",
        "  return model\r\n",
        "EPOCHS = 500\r\n",
        "batch_size = 16\r\n",
        "model = build_model1_two_hidden_layers()\r\n",
        "model.summary()\r\n",
        "\r\n",
        "with tf.device('/CPU:0'):\r\n",
        "  history = model.fit(X_train,y_train,batch_size=batch_size,epochs=EPOCHS,verbose=1,shuffle=False, steps_per_epoch = int(X_train.shape[0]/batch_size),validation_data=(X_valid,y_valid))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_14 (Dense)             (None, 32)                480       \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 513\n",
            "Trainable params: 513\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "37/37 [==============================] - 1s 10ms/step - loss: 0.8289 - accuracy: 0.5602 - val_loss: 0.8093 - val_accuracy: 0.5700\n",
            "Epoch 2/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.8146 - accuracy: 0.5663 - val_loss: 0.8067 - val_accuracy: 0.5750\n",
            "Epoch 3/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.8134 - accuracy: 0.5507 - val_loss: 0.8041 - val_accuracy: 0.5750\n",
            "Epoch 4/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.8199 - accuracy: 0.5544 - val_loss: 0.8015 - val_accuracy: 0.5750\n",
            "Epoch 5/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.8315 - accuracy: 0.5489 - val_loss: 0.7989 - val_accuracy: 0.5800\n",
            "Epoch 6/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.8297 - accuracy: 0.5242 - val_loss: 0.7963 - val_accuracy: 0.5800\n",
            "Epoch 7/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.8258 - accuracy: 0.5249 - val_loss: 0.7938 - val_accuracy: 0.5900\n",
            "Epoch 8/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.8130 - accuracy: 0.5388 - val_loss: 0.7912 - val_accuracy: 0.5950\n",
            "Epoch 9/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.7761 - accuracy: 0.5695 - val_loss: 0.7887 - val_accuracy: 0.5950\n",
            "Epoch 10/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.7792 - accuracy: 0.5646 - val_loss: 0.7863 - val_accuracy: 0.6000\n",
            "Epoch 11/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.7857 - accuracy: 0.5719 - val_loss: 0.7838 - val_accuracy: 0.6000\n",
            "Epoch 12/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.7831 - accuracy: 0.5703 - val_loss: 0.7814 - val_accuracy: 0.6000\n",
            "Epoch 13/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.7979 - accuracy: 0.5622 - val_loss: 0.7789 - val_accuracy: 0.6050\n",
            "Epoch 14/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.7617 - accuracy: 0.5855 - val_loss: 0.7765 - val_accuracy: 0.6050\n",
            "Epoch 15/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.7749 - accuracy: 0.5697 - val_loss: 0.7741 - val_accuracy: 0.6050\n",
            "Epoch 16/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.7694 - accuracy: 0.5798 - val_loss: 0.7718 - val_accuracy: 0.6050\n",
            "Epoch 17/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.7791 - accuracy: 0.5870 - val_loss: 0.7694 - val_accuracy: 0.6100\n",
            "Epoch 18/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.7623 - accuracy: 0.5902 - val_loss: 0.7670 - val_accuracy: 0.6100\n",
            "Epoch 19/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.7634 - accuracy: 0.5999 - val_loss: 0.7647 - val_accuracy: 0.6100\n",
            "Epoch 20/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.6287 - val_loss: 0.7624 - val_accuracy: 0.6100\n",
            "Epoch 21/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.7314 - accuracy: 0.6377 - val_loss: 0.7601 - val_accuracy: 0.6100\n",
            "Epoch 22/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.7488 - accuracy: 0.6195 - val_loss: 0.7579 - val_accuracy: 0.6100\n",
            "Epoch 23/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.7596 - accuracy: 0.6205 - val_loss: 0.7556 - val_accuracy: 0.6100\n",
            "Epoch 24/500\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 0.7434 - accuracy: 0.6213 - val_loss: 0.7534 - val_accuracy: 0.6100\n",
            "Epoch 25/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.7458 - accuracy: 0.6218 - val_loss: 0.7512 - val_accuracy: 0.6150\n",
            "Epoch 26/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.7539 - accuracy: 0.6105 - val_loss: 0.7490 - val_accuracy: 0.6150\n",
            "Epoch 27/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.7423 - accuracy: 0.6210 - val_loss: 0.7468 - val_accuracy: 0.6250\n",
            "Epoch 28/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.7347 - accuracy: 0.6213 - val_loss: 0.7447 - val_accuracy: 0.6250\n",
            "Epoch 29/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.7424 - accuracy: 0.6108 - val_loss: 0.7426 - val_accuracy: 0.6200\n",
            "Epoch 30/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.7468 - accuracy: 0.6116 - val_loss: 0.7404 - val_accuracy: 0.6200\n",
            "Epoch 31/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.7069 - accuracy: 0.6507 - val_loss: 0.7383 - val_accuracy: 0.6200\n",
            "Epoch 32/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.7173 - accuracy: 0.6468 - val_loss: 0.7362 - val_accuracy: 0.6200\n",
            "Epoch 33/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.7293 - accuracy: 0.6270 - val_loss: 0.7341 - val_accuracy: 0.6200\n",
            "Epoch 34/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.7264 - accuracy: 0.6157 - val_loss: 0.7321 - val_accuracy: 0.6250\n",
            "Epoch 35/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.7295 - accuracy: 0.6043 - val_loss: 0.7301 - val_accuracy: 0.6250\n",
            "Epoch 36/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.7537 - accuracy: 0.5925 - val_loss: 0.7281 - val_accuracy: 0.6250\n",
            "Epoch 37/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.7345 - accuracy: 0.6067 - val_loss: 0.7261 - val_accuracy: 0.6250\n",
            "Epoch 38/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.7171 - accuracy: 0.6302 - val_loss: 0.7241 - val_accuracy: 0.6250\n",
            "Epoch 39/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.7313 - accuracy: 0.6360 - val_loss: 0.7221 - val_accuracy: 0.6250\n",
            "Epoch 40/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.7208 - accuracy: 0.6355 - val_loss: 0.7201 - val_accuracy: 0.6250\n",
            "Epoch 41/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.7209 - accuracy: 0.6173 - val_loss: 0.7182 - val_accuracy: 0.6250\n",
            "Epoch 42/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.7234 - accuracy: 0.6121 - val_loss: 0.7163 - val_accuracy: 0.6250\n",
            "Epoch 43/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.7304 - accuracy: 0.6012 - val_loss: 0.7144 - val_accuracy: 0.6400\n",
            "Epoch 44/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.7315 - accuracy: 0.5878 - val_loss: 0.7125 - val_accuracy: 0.6400\n",
            "Epoch 45/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.7278 - accuracy: 0.5738 - val_loss: 0.7106 - val_accuracy: 0.6400\n",
            "Epoch 46/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.7180 - accuracy: 0.5925 - val_loss: 0.7087 - val_accuracy: 0.6400\n",
            "Epoch 47/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.6898 - accuracy: 0.6166 - val_loss: 0.7068 - val_accuracy: 0.6400\n",
            "Epoch 48/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.6143 - val_loss: 0.7050 - val_accuracy: 0.6450\n",
            "Epoch 49/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.6955 - accuracy: 0.6282 - val_loss: 0.7032 - val_accuracy: 0.6500\n",
            "Epoch 50/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.6198 - val_loss: 0.7014 - val_accuracy: 0.6500\n",
            "Epoch 51/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.7077 - accuracy: 0.6122 - val_loss: 0.6996 - val_accuracy: 0.6600\n",
            "Epoch 52/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.6770 - accuracy: 0.6349 - val_loss: 0.6978 - val_accuracy: 0.6700\n",
            "Epoch 53/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.6941 - accuracy: 0.6190 - val_loss: 0.6960 - val_accuracy: 0.6700\n",
            "Epoch 54/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.6847 - accuracy: 0.6271 - val_loss: 0.6943 - val_accuracy: 0.6700\n",
            "Epoch 55/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.6894 - accuracy: 0.6471 - val_loss: 0.6925 - val_accuracy: 0.6700\n",
            "Epoch 56/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.6807 - accuracy: 0.6421 - val_loss: 0.6908 - val_accuracy: 0.6700\n",
            "Epoch 57/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.6840 - accuracy: 0.6436 - val_loss: 0.6890 - val_accuracy: 0.6800\n",
            "Epoch 58/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.6618 - accuracy: 0.6611 - val_loss: 0.6873 - val_accuracy: 0.6800\n",
            "Epoch 59/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.6562 - accuracy: 0.6839 - val_loss: 0.6857 - val_accuracy: 0.6800\n",
            "Epoch 60/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.6689 - accuracy: 0.6670 - val_loss: 0.6840 - val_accuracy: 0.6750\n",
            "Epoch 61/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.6797 - accuracy: 0.6657 - val_loss: 0.6823 - val_accuracy: 0.6750\n",
            "Epoch 62/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.6694 - accuracy: 0.6616 - val_loss: 0.6807 - val_accuracy: 0.6800\n",
            "Epoch 63/500\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.6701 - accuracy: 0.6586 - val_loss: 0.6790 - val_accuracy: 0.6800\n",
            "Epoch 64/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.6787 - accuracy: 0.6547 - val_loss: 0.6774 - val_accuracy: 0.6800\n",
            "Epoch 65/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.6699 - accuracy: 0.6631 - val_loss: 0.6758 - val_accuracy: 0.6850\n",
            "Epoch 66/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.6619 - accuracy: 0.6714 - val_loss: 0.6742 - val_accuracy: 0.6850\n",
            "Epoch 67/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.6685 - accuracy: 0.6672 - val_loss: 0.6726 - val_accuracy: 0.6850\n",
            "Epoch 68/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.6692 - accuracy: 0.6558 - val_loss: 0.6710 - val_accuracy: 0.6850\n",
            "Epoch 69/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.6387 - accuracy: 0.6903 - val_loss: 0.6695 - val_accuracy: 0.6850\n",
            "Epoch 70/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.6475 - accuracy: 0.6803 - val_loss: 0.6679 - val_accuracy: 0.6850\n",
            "Epoch 71/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.6553 - accuracy: 0.6610 - val_loss: 0.6664 - val_accuracy: 0.6900\n",
            "Epoch 72/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.6567 - accuracy: 0.6540 - val_loss: 0.6649 - val_accuracy: 0.6900\n",
            "Epoch 73/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.6582 - accuracy: 0.6394 - val_loss: 0.6634 - val_accuracy: 0.6950\n",
            "Epoch 74/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.6749 - accuracy: 0.6401 - val_loss: 0.6619 - val_accuracy: 0.6950\n",
            "Epoch 75/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.6595 - accuracy: 0.6546 - val_loss: 0.6604 - val_accuracy: 0.6950\n",
            "Epoch 76/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.6476 - accuracy: 0.6718 - val_loss: 0.6589 - val_accuracy: 0.7000\n",
            "Epoch 77/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.6595 - accuracy: 0.6791 - val_loss: 0.6574 - val_accuracy: 0.7000\n",
            "Epoch 78/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.6517 - accuracy: 0.6771 - val_loss: 0.6559 - val_accuracy: 0.7000\n",
            "Epoch 79/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.6531 - accuracy: 0.6591 - val_loss: 0.6545 - val_accuracy: 0.7000\n",
            "Epoch 80/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.6524 - accuracy: 0.6507 - val_loss: 0.6531 - val_accuracy: 0.7000\n",
            "Epoch 81/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.6556 - accuracy: 0.6508 - val_loss: 0.6517 - val_accuracy: 0.7000\n",
            "Epoch 82/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.6593 - accuracy: 0.6348 - val_loss: 0.6502 - val_accuracy: 0.7000\n",
            "Epoch 83/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.6559 - accuracy: 0.6292 - val_loss: 0.6488 - val_accuracy: 0.7000\n",
            "Epoch 84/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.6480 - accuracy: 0.6426 - val_loss: 0.6474 - val_accuracy: 0.7000\n",
            "Epoch 85/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.6264 - accuracy: 0.6579 - val_loss: 0.6460 - val_accuracy: 0.7050\n",
            "Epoch 86/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.6311 - accuracy: 0.6528 - val_loss: 0.6447 - val_accuracy: 0.7050\n",
            "Epoch 87/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.6291 - accuracy: 0.6652 - val_loss: 0.6433 - val_accuracy: 0.7100\n",
            "Epoch 88/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.6267 - accuracy: 0.6616 - val_loss: 0.6420 - val_accuracy: 0.7100\n",
            "Epoch 89/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.6410 - accuracy: 0.6687 - val_loss: 0.6406 - val_accuracy: 0.7100\n",
            "Epoch 90/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.6143 - accuracy: 0.6813 - val_loss: 0.6392 - val_accuracy: 0.7100\n",
            "Epoch 91/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.6347 - accuracy: 0.6591 - val_loss: 0.6379 - val_accuracy: 0.7100\n",
            "Epoch 92/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.6224 - accuracy: 0.6785 - val_loss: 0.6366 - val_accuracy: 0.7100\n",
            "Epoch 93/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.6233 - accuracy: 0.6987 - val_loss: 0.6353 - val_accuracy: 0.7100\n",
            "Epoch 94/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.6210 - accuracy: 0.6797 - val_loss: 0.6340 - val_accuracy: 0.7150\n",
            "Epoch 95/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.6259 - accuracy: 0.6879 - val_loss: 0.6327 - val_accuracy: 0.7150\n",
            "Epoch 96/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.6088 - accuracy: 0.7031 - val_loss: 0.6314 - val_accuracy: 0.7150\n",
            "Epoch 97/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.6016 - accuracy: 0.7271 - val_loss: 0.6302 - val_accuracy: 0.7200\n",
            "Epoch 98/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.6104 - accuracy: 0.7268 - val_loss: 0.6289 - val_accuracy: 0.7200\n",
            "Epoch 99/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.6209 - accuracy: 0.7209 - val_loss: 0.6277 - val_accuracy: 0.7200\n",
            "Epoch 100/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.6147 - accuracy: 0.7098 - val_loss: 0.6264 - val_accuracy: 0.7200\n",
            "Epoch 101/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.6143 - accuracy: 0.7224 - val_loss: 0.6252 - val_accuracy: 0.7250\n",
            "Epoch 102/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.6228 - accuracy: 0.7092 - val_loss: 0.6240 - val_accuracy: 0.7250\n",
            "Epoch 103/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.6163 - accuracy: 0.7078 - val_loss: 0.6228 - val_accuracy: 0.7250\n",
            "Epoch 104/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.6079 - accuracy: 0.7197 - val_loss: 0.6216 - val_accuracy: 0.7250\n",
            "Epoch 105/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.6135 - accuracy: 0.7082 - val_loss: 0.6204 - val_accuracy: 0.7250\n",
            "Epoch 106/500\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 0.6113 - accuracy: 0.6938 - val_loss: 0.6192 - val_accuracy: 0.7250\n",
            "Epoch 107/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5880 - accuracy: 0.7342 - val_loss: 0.6180 - val_accuracy: 0.7250\n",
            "Epoch 108/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5955 - accuracy: 0.7206 - val_loss: 0.6169 - val_accuracy: 0.7250\n",
            "Epoch 109/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5999 - accuracy: 0.7106 - val_loss: 0.6157 - val_accuracy: 0.7200\n",
            "Epoch 110/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.6051 - accuracy: 0.7029 - val_loss: 0.6145 - val_accuracy: 0.7200\n",
            "Epoch 111/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.6054 - accuracy: 0.7031 - val_loss: 0.6134 - val_accuracy: 0.7200\n",
            "Epoch 112/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.6165 - accuracy: 0.7094 - val_loss: 0.6123 - val_accuracy: 0.7200\n",
            "Epoch 113/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.6038 - accuracy: 0.7138 - val_loss: 0.6111 - val_accuracy: 0.7150\n",
            "Epoch 114/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5962 - accuracy: 0.7321 - val_loss: 0.6100 - val_accuracy: 0.7150\n",
            "Epoch 115/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.6063 - accuracy: 0.7320 - val_loss: 0.6089 - val_accuracy: 0.7200\n",
            "Epoch 116/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.6007 - accuracy: 0.7273 - val_loss: 0.6078 - val_accuracy: 0.7200\n",
            "Epoch 117/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.6033 - accuracy: 0.7087 - val_loss: 0.6067 - val_accuracy: 0.7200\n",
            "Epoch 118/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.6002 - accuracy: 0.7240 - val_loss: 0.6057 - val_accuracy: 0.7150\n",
            "Epoch 119/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.6002 - accuracy: 0.7128 - val_loss: 0.6046 - val_accuracy: 0.7150\n",
            "Epoch 120/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.6061 - accuracy: 0.6975 - val_loss: 0.6035 - val_accuracy: 0.7150\n",
            "Epoch 121/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.6030 - accuracy: 0.6824 - val_loss: 0.6024 - val_accuracy: 0.7150\n",
            "Epoch 122/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5963 - accuracy: 0.6790 - val_loss: 0.6013 - val_accuracy: 0.7150\n",
            "Epoch 123/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5798 - accuracy: 0.6881 - val_loss: 0.6003 - val_accuracy: 0.7100\n",
            "Epoch 124/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5847 - accuracy: 0.6762 - val_loss: 0.5993 - val_accuracy: 0.7100\n",
            "Epoch 125/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5799 - accuracy: 0.6932 - val_loss: 0.5982 - val_accuracy: 0.7100\n",
            "Epoch 126/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5775 - accuracy: 0.6982 - val_loss: 0.5972 - val_accuracy: 0.7100\n",
            "Epoch 127/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5914 - accuracy: 0.7095 - val_loss: 0.5962 - val_accuracy: 0.7100\n",
            "Epoch 128/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5675 - accuracy: 0.7188 - val_loss: 0.5951 - val_accuracy: 0.7150\n",
            "Epoch 129/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5906 - accuracy: 0.6986 - val_loss: 0.5941 - val_accuracy: 0.7200\n",
            "Epoch 130/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5764 - accuracy: 0.7134 - val_loss: 0.5932 - val_accuracy: 0.7200\n",
            "Epoch 131/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5743 - accuracy: 0.7313 - val_loss: 0.5921 - val_accuracy: 0.7200\n",
            "Epoch 132/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5769 - accuracy: 0.6954 - val_loss: 0.5912 - val_accuracy: 0.7200\n",
            "Epoch 133/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5831 - accuracy: 0.7111 - val_loss: 0.5901 - val_accuracy: 0.7200\n",
            "Epoch 134/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5702 - accuracy: 0.7220 - val_loss: 0.5892 - val_accuracy: 0.7200\n",
            "Epoch 135/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5615 - accuracy: 0.7444 - val_loss: 0.5882 - val_accuracy: 0.7200\n",
            "Epoch 136/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5672 - accuracy: 0.7414 - val_loss: 0.5873 - val_accuracy: 0.7200\n",
            "Epoch 137/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5773 - accuracy: 0.7339 - val_loss: 0.5863 - val_accuracy: 0.7200\n",
            "Epoch 138/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5740 - accuracy: 0.7216 - val_loss: 0.5854 - val_accuracy: 0.7200\n",
            "Epoch 139/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5728 - accuracy: 0.7330 - val_loss: 0.5844 - val_accuracy: 0.7200\n",
            "Epoch 140/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5809 - accuracy: 0.7322 - val_loss: 0.5835 - val_accuracy: 0.7200\n",
            "Epoch 141/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5760 - accuracy: 0.7197 - val_loss: 0.5826 - val_accuracy: 0.7200\n",
            "Epoch 142/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5674 - accuracy: 0.7324 - val_loss: 0.5817 - val_accuracy: 0.7200\n",
            "Epoch 143/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5721 - accuracy: 0.7269 - val_loss: 0.5808 - val_accuracy: 0.7200\n",
            "Epoch 144/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5675 - accuracy: 0.7168 - val_loss: 0.5798 - val_accuracy: 0.7200\n",
            "Epoch 145/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5499 - accuracy: 0.7435 - val_loss: 0.5789 - val_accuracy: 0.7200\n",
            "Epoch 146/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5563 - accuracy: 0.7278 - val_loss: 0.5780 - val_accuracy: 0.7200\n",
            "Epoch 147/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5582 - accuracy: 0.7244 - val_loss: 0.5771 - val_accuracy: 0.7200\n",
            "Epoch 148/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5663 - accuracy: 0.7196 - val_loss: 0.5762 - val_accuracy: 0.7200\n",
            "Epoch 149/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5659 - accuracy: 0.7274 - val_loss: 0.5754 - val_accuracy: 0.7200\n",
            "Epoch 150/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5727 - accuracy: 0.7442 - val_loss: 0.5745 - val_accuracy: 0.7200\n",
            "Epoch 151/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5618 - accuracy: 0.7458 - val_loss: 0.5736 - val_accuracy: 0.7200\n",
            "Epoch 152/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5576 - accuracy: 0.7619 - val_loss: 0.5728 - val_accuracy: 0.7200\n",
            "Epoch 153/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5665 - accuracy: 0.7509 - val_loss: 0.5719 - val_accuracy: 0.7200\n",
            "Epoch 154/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5624 - accuracy: 0.7441 - val_loss: 0.5710 - val_accuracy: 0.7200\n",
            "Epoch 155/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5662 - accuracy: 0.7323 - val_loss: 0.5702 - val_accuracy: 0.7150\n",
            "Epoch 156/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5612 - accuracy: 0.7437 - val_loss: 0.5694 - val_accuracy: 0.7200\n",
            "Epoch 157/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5587 - accuracy: 0.7314 - val_loss: 0.5685 - val_accuracy: 0.7200\n",
            "Epoch 158/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5665 - accuracy: 0.7071 - val_loss: 0.5677 - val_accuracy: 0.7200\n",
            "Epoch 159/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5637 - accuracy: 0.6948 - val_loss: 0.5669 - val_accuracy: 0.7250\n",
            "Epoch 160/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5576 - accuracy: 0.6905 - val_loss: 0.5660 - val_accuracy: 0.7300\n",
            "Epoch 161/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5450 - accuracy: 0.6998 - val_loss: 0.5652 - val_accuracy: 0.7300\n",
            "Epoch 162/500\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.5500 - accuracy: 0.6927 - val_loss: 0.5644 - val_accuracy: 0.7300\n",
            "Epoch 163/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5430 - accuracy: 0.7074 - val_loss: 0.5636 - val_accuracy: 0.7300\n",
            "Epoch 164/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5404 - accuracy: 0.7108 - val_loss: 0.5628 - val_accuracy: 0.7300\n",
            "Epoch 165/500\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.5539 - accuracy: 0.7280 - val_loss: 0.5620 - val_accuracy: 0.7300\n",
            "Epoch 166/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5319 - accuracy: 0.7349 - val_loss: 0.5612 - val_accuracy: 0.7300\n",
            "Epoch 167/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5575 - accuracy: 0.7060 - val_loss: 0.5604 - val_accuracy: 0.7300\n",
            "Epoch 168/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5418 - accuracy: 0.7205 - val_loss: 0.5597 - val_accuracy: 0.7350\n",
            "Epoch 169/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5374 - accuracy: 0.7439 - val_loss: 0.5589 - val_accuracy: 0.7400\n",
            "Epoch 170/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5437 - accuracy: 0.7169 - val_loss: 0.5581 - val_accuracy: 0.7450\n",
            "Epoch 171/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5510 - accuracy: 0.7294 - val_loss: 0.5573 - val_accuracy: 0.7450\n",
            "Epoch 172/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5416 - accuracy: 0.7305 - val_loss: 0.5566 - val_accuracy: 0.7450\n",
            "Epoch 173/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5315 - accuracy: 0.7493 - val_loss: 0.5558 - val_accuracy: 0.7450\n",
            "Epoch 174/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5348 - accuracy: 0.7460 - val_loss: 0.5551 - val_accuracy: 0.7450\n",
            "Epoch 175/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5443 - accuracy: 0.7464 - val_loss: 0.5543 - val_accuracy: 0.7450\n",
            "Epoch 176/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5430 - accuracy: 0.7389 - val_loss: 0.5536 - val_accuracy: 0.7450\n",
            "Epoch 177/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5412 - accuracy: 0.7475 - val_loss: 0.5529 - val_accuracy: 0.7450\n",
            "Epoch 178/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5488 - accuracy: 0.7469 - val_loss: 0.5521 - val_accuracy: 0.7450\n",
            "Epoch 179/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5452 - accuracy: 0.7398 - val_loss: 0.5514 - val_accuracy: 0.7450\n",
            "Epoch 180/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5364 - accuracy: 0.7459 - val_loss: 0.5507 - val_accuracy: 0.7450\n",
            "Epoch 181/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5403 - accuracy: 0.7420 - val_loss: 0.5500 - val_accuracy: 0.7450\n",
            "Epoch 182/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5338 - accuracy: 0.7462 - val_loss: 0.5492 - val_accuracy: 0.7450\n",
            "Epoch 183/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5207 - accuracy: 0.7539 - val_loss: 0.5485 - val_accuracy: 0.7450\n",
            "Epoch 184/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5263 - accuracy: 0.7535 - val_loss: 0.5478 - val_accuracy: 0.7450\n",
            "Epoch 185/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5261 - accuracy: 0.7532 - val_loss: 0.5471 - val_accuracy: 0.7450\n",
            "Epoch 186/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5367 - accuracy: 0.7390 - val_loss: 0.5464 - val_accuracy: 0.7450\n",
            "Epoch 187/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5357 - accuracy: 0.7430 - val_loss: 0.5457 - val_accuracy: 0.7450\n",
            "Epoch 188/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5392 - accuracy: 0.7585 - val_loss: 0.5450 - val_accuracy: 0.7450\n",
            "Epoch 189/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5297 - accuracy: 0.7562 - val_loss: 0.5444 - val_accuracy: 0.7450\n",
            "Epoch 190/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5280 - accuracy: 0.7694 - val_loss: 0.5437 - val_accuracy: 0.7450\n",
            "Epoch 191/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5360 - accuracy: 0.7588 - val_loss: 0.5430 - val_accuracy: 0.7450\n",
            "Epoch 192/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5330 - accuracy: 0.7503 - val_loss: 0.5423 - val_accuracy: 0.7500\n",
            "Epoch 193/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5381 - accuracy: 0.7378 - val_loss: 0.5416 - val_accuracy: 0.7500\n",
            "Epoch 194/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5317 - accuracy: 0.7544 - val_loss: 0.5410 - val_accuracy: 0.7500\n",
            "Epoch 195/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5270 - accuracy: 0.7398 - val_loss: 0.5403 - val_accuracy: 0.7500\n",
            "Epoch 196/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5364 - accuracy: 0.7177 - val_loss: 0.5397 - val_accuracy: 0.7500\n",
            "Epoch 197/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5339 - accuracy: 0.7113 - val_loss: 0.5390 - val_accuracy: 0.7500\n",
            "Epoch 198/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5280 - accuracy: 0.7186 - val_loss: 0.5383 - val_accuracy: 0.7500\n",
            "Epoch 199/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5184 - accuracy: 0.7238 - val_loss: 0.5377 - val_accuracy: 0.7500\n",
            "Epoch 200/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5234 - accuracy: 0.7195 - val_loss: 0.5371 - val_accuracy: 0.7500\n",
            "Epoch 201/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5147 - accuracy: 0.7304 - val_loss: 0.5364 - val_accuracy: 0.7500\n",
            "Epoch 202/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5119 - accuracy: 0.7312 - val_loss: 0.5358 - val_accuracy: 0.7500\n",
            "Epoch 203/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5250 - accuracy: 0.7464 - val_loss: 0.5352 - val_accuracy: 0.7500\n",
            "Epoch 204/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7655 - val_loss: 0.5345 - val_accuracy: 0.7500\n",
            "Epoch 205/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5321 - accuracy: 0.7389 - val_loss: 0.5339 - val_accuracy: 0.7500\n",
            "Epoch 206/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5151 - accuracy: 0.7481 - val_loss: 0.5333 - val_accuracy: 0.7500\n",
            "Epoch 207/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.7635 - val_loss: 0.5326 - val_accuracy: 0.7550\n",
            "Epoch 208/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5183 - accuracy: 0.7387 - val_loss: 0.5320 - val_accuracy: 0.7550\n",
            "Epoch 209/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5264 - accuracy: 0.7487 - val_loss: 0.5314 - val_accuracy: 0.7550\n",
            "Epoch 210/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5198 - accuracy: 0.7481 - val_loss: 0.5308 - val_accuracy: 0.7550\n",
            "Epoch 211/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.7620 - val_loss: 0.5302 - val_accuracy: 0.7600\n",
            "Epoch 212/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.7586 - val_loss: 0.5296 - val_accuracy: 0.7600\n",
            "Epoch 213/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5187 - accuracy: 0.7710 - val_loss: 0.5290 - val_accuracy: 0.7650\n",
            "Epoch 214/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5189 - accuracy: 0.7597 - val_loss: 0.5284 - val_accuracy: 0.7650\n",
            "Epoch 215/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5167 - accuracy: 0.7659 - val_loss: 0.5278 - val_accuracy: 0.7650\n",
            "Epoch 216/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5235 - accuracy: 0.7649 - val_loss: 0.5272 - val_accuracy: 0.7650\n",
            "Epoch 217/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5211 - accuracy: 0.7562 - val_loss: 0.5266 - val_accuracy: 0.7650\n",
            "Epoch 218/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.7640 - val_loss: 0.5261 - val_accuracy: 0.7650\n",
            "Epoch 219/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5153 - accuracy: 0.7616 - val_loss: 0.5255 - val_accuracy: 0.7650\n",
            "Epoch 220/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7674 - val_loss: 0.5249 - val_accuracy: 0.7650\n",
            "Epoch 221/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4977 - accuracy: 0.7713 - val_loss: 0.5243 - val_accuracy: 0.7650\n",
            "Epoch 222/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5026 - accuracy: 0.7674 - val_loss: 0.5238 - val_accuracy: 0.7650\n",
            "Epoch 223/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5009 - accuracy: 0.7656 - val_loss: 0.5232 - val_accuracy: 0.7650\n",
            "Epoch 224/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5136 - accuracy: 0.7502 - val_loss: 0.5226 - val_accuracy: 0.7650\n",
            "Epoch 225/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5121 - accuracy: 0.7522 - val_loss: 0.5221 - val_accuracy: 0.7650\n",
            "Epoch 226/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5131 - accuracy: 0.7689 - val_loss: 0.5215 - val_accuracy: 0.7650\n",
            "Epoch 227/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7726 - val_loss: 0.5210 - val_accuracy: 0.7650\n",
            "Epoch 228/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5048 - accuracy: 0.7834 - val_loss: 0.5204 - val_accuracy: 0.7650\n",
            "Epoch 229/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5122 - accuracy: 0.7712 - val_loss: 0.5199 - val_accuracy: 0.7650\n",
            "Epoch 230/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5100 - accuracy: 0.7717 - val_loss: 0.5193 - val_accuracy: 0.7650\n",
            "Epoch 231/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5163 - accuracy: 0.7549 - val_loss: 0.5188 - val_accuracy: 0.7650\n",
            "Epoch 232/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.7647 - val_loss: 0.5183 - val_accuracy: 0.7650\n",
            "Epoch 233/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5022 - accuracy: 0.7419 - val_loss: 0.5177 - val_accuracy: 0.7650\n",
            "Epoch 234/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5131 - accuracy: 0.7246 - val_loss: 0.5172 - val_accuracy: 0.7650\n",
            "Epoch 235/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5108 - accuracy: 0.7250 - val_loss: 0.5166 - val_accuracy: 0.7650\n",
            "Epoch 236/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7299 - val_loss: 0.5161 - val_accuracy: 0.7650\n",
            "Epoch 237/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4977 - accuracy: 0.7328 - val_loss: 0.5156 - val_accuracy: 0.7650\n",
            "Epoch 238/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5026 - accuracy: 0.7347 - val_loss: 0.5151 - val_accuracy: 0.7700\n",
            "Epoch 239/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4925 - accuracy: 0.7432 - val_loss: 0.5145 - val_accuracy: 0.7700\n",
            "Epoch 240/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4894 - accuracy: 0.7426 - val_loss: 0.5140 - val_accuracy: 0.7750\n",
            "Epoch 241/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.5023 - accuracy: 0.7566 - val_loss: 0.5135 - val_accuracy: 0.7750\n",
            "Epoch 242/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4825 - accuracy: 0.7748 - val_loss: 0.5130 - val_accuracy: 0.7750\n",
            "Epoch 243/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5121 - accuracy: 0.7471 - val_loss: 0.5125 - val_accuracy: 0.7750\n",
            "Epoch 244/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4940 - accuracy: 0.7557 - val_loss: 0.5120 - val_accuracy: 0.7750\n",
            "Epoch 245/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4863 - accuracy: 0.7685 - val_loss: 0.5115 - val_accuracy: 0.7750\n",
            "Epoch 246/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4982 - accuracy: 0.7434 - val_loss: 0.5110 - val_accuracy: 0.7750\n",
            "Epoch 247/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5069 - accuracy: 0.7508 - val_loss: 0.5104 - val_accuracy: 0.7750\n",
            "Epoch 248/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5028 - accuracy: 0.7385 - val_loss: 0.5100 - val_accuracy: 0.7750\n",
            "Epoch 249/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4903 - accuracy: 0.7553 - val_loss: 0.5095 - val_accuracy: 0.7750\n",
            "Epoch 250/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4901 - accuracy: 0.7603 - val_loss: 0.5090 - val_accuracy: 0.7750\n",
            "Epoch 251/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4985 - accuracy: 0.7649 - val_loss: 0.5085 - val_accuracy: 0.7750\n",
            "Epoch 252/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4996 - accuracy: 0.7549 - val_loss: 0.5080 - val_accuracy: 0.7750\n",
            "Epoch 253/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4971 - accuracy: 0.7617 - val_loss: 0.5075 - val_accuracy: 0.7750\n",
            "Epoch 254/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5032 - accuracy: 0.7671 - val_loss: 0.5070 - val_accuracy: 0.7750\n",
            "Epoch 255/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.5018 - accuracy: 0.7571 - val_loss: 0.5066 - val_accuracy: 0.7750\n",
            "Epoch 256/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4928 - accuracy: 0.7639 - val_loss: 0.5061 - val_accuracy: 0.7750\n",
            "Epoch 257/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4952 - accuracy: 0.7616 - val_loss: 0.5056 - val_accuracy: 0.7750\n",
            "Epoch 258/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4860 - accuracy: 0.7742 - val_loss: 0.5051 - val_accuracy: 0.7750\n",
            "Epoch 259/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4792 - accuracy: 0.7771 - val_loss: 0.5047 - val_accuracy: 0.7700\n",
            "Epoch 260/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4836 - accuracy: 0.7729 - val_loss: 0.5042 - val_accuracy: 0.7700\n",
            "Epoch 261/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4806 - accuracy: 0.7703 - val_loss: 0.5037 - val_accuracy: 0.7700\n",
            "Epoch 262/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4950 - accuracy: 0.7683 - val_loss: 0.5033 - val_accuracy: 0.7700\n",
            "Epoch 263/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4933 - accuracy: 0.7666 - val_loss: 0.5028 - val_accuracy: 0.7700\n",
            "Epoch 264/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4923 - accuracy: 0.7798 - val_loss: 0.5024 - val_accuracy: 0.7700\n",
            "Epoch 265/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.7822 - val_loss: 0.5019 - val_accuracy: 0.7700\n",
            "Epoch 266/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4862 - accuracy: 0.7921 - val_loss: 0.5014 - val_accuracy: 0.7700\n",
            "Epoch 267/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4930 - accuracy: 0.7860 - val_loss: 0.5010 - val_accuracy: 0.7700\n",
            "Epoch 268/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4915 - accuracy: 0.7838 - val_loss: 0.5005 - val_accuracy: 0.7700\n",
            "Epoch 269/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4990 - accuracy: 0.7728 - val_loss: 0.5001 - val_accuracy: 0.7700\n",
            "Epoch 270/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4904 - accuracy: 0.7796 - val_loss: 0.4997 - val_accuracy: 0.7700\n",
            "Epoch 271/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4824 - accuracy: 0.7550 - val_loss: 0.4992 - val_accuracy: 0.7700\n",
            "Epoch 272/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4945 - accuracy: 0.7364 - val_loss: 0.4988 - val_accuracy: 0.7700\n",
            "Epoch 273/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4925 - accuracy: 0.7348 - val_loss: 0.4983 - val_accuracy: 0.7700\n",
            "Epoch 274/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4866 - accuracy: 0.7389 - val_loss: 0.4979 - val_accuracy: 0.7700\n",
            "Epoch 275/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4812 - accuracy: 0.7417 - val_loss: 0.4974 - val_accuracy: 0.7700\n",
            "Epoch 276/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4858 - accuracy: 0.7439 - val_loss: 0.4970 - val_accuracy: 0.7700\n",
            "Epoch 277/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4747 - accuracy: 0.7658 - val_loss: 0.4966 - val_accuracy: 0.7700\n",
            "Epoch 278/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4713 - accuracy: 0.7613 - val_loss: 0.4962 - val_accuracy: 0.7700\n",
            "Epoch 279/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4838 - accuracy: 0.7731 - val_loss: 0.4957 - val_accuracy: 0.7700\n",
            "Epoch 280/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4647 - accuracy: 0.7898 - val_loss: 0.4953 - val_accuracy: 0.7700\n",
            "Epoch 281/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4959 - accuracy: 0.7557 - val_loss: 0.4949 - val_accuracy: 0.7700\n",
            "Epoch 282/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4770 - accuracy: 0.7619 - val_loss: 0.4944 - val_accuracy: 0.7700\n",
            "Epoch 283/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4681 - accuracy: 0.7746 - val_loss: 0.4940 - val_accuracy: 0.7700\n",
            "Epoch 284/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4820 - accuracy: 0.7491 - val_loss: 0.4936 - val_accuracy: 0.7700\n",
            "Epoch 285/500\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 0.4913 - accuracy: 0.7585 - val_loss: 0.4932 - val_accuracy: 0.7700\n",
            "Epoch 286/500\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 0.4891 - accuracy: 0.7432 - val_loss: 0.4928 - val_accuracy: 0.7700\n",
            "Epoch 287/500\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 0.4756 - accuracy: 0.7595 - val_loss: 0.4923 - val_accuracy: 0.7700\n",
            "Epoch 288/500\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 0.4742 - accuracy: 0.7710 - val_loss: 0.4919 - val_accuracy: 0.7700\n",
            "Epoch 289/500\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 0.4821 - accuracy: 0.7736 - val_loss: 0.4915 - val_accuracy: 0.7700\n",
            "Epoch 290/500\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 0.4838 - accuracy: 0.7624 - val_loss: 0.4911 - val_accuracy: 0.7700\n",
            "Epoch 291/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4811 - accuracy: 0.7753 - val_loss: 0.4907 - val_accuracy: 0.7700\n",
            "Epoch 292/500\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 0.4865 - accuracy: 0.7779 - val_loss: 0.4903 - val_accuracy: 0.7700\n",
            "Epoch 293/500\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 0.4859 - accuracy: 0.7710 - val_loss: 0.4899 - val_accuracy: 0.7700\n",
            "Epoch 294/500\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 0.4769 - accuracy: 0.7832 - val_loss: 0.4895 - val_accuracy: 0.7700\n",
            "Epoch 295/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4787 - accuracy: 0.7781 - val_loss: 0.4891 - val_accuracy: 0.7700\n",
            "Epoch 296/500\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 0.4684 - accuracy: 0.7907 - val_loss: 0.4887 - val_accuracy: 0.7700\n",
            "Epoch 297/500\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 0.4639 - accuracy: 0.7918 - val_loss: 0.4883 - val_accuracy: 0.7700\n",
            "Epoch 298/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4678 - accuracy: 0.7864 - val_loss: 0.4880 - val_accuracy: 0.7700\n",
            "Epoch 299/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4640 - accuracy: 0.7827 - val_loss: 0.4875 - val_accuracy: 0.7700\n",
            "Epoch 300/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4797 - accuracy: 0.7797 - val_loss: 0.4872 - val_accuracy: 0.7700\n",
            "Epoch 301/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4778 - accuracy: 0.7770 - val_loss: 0.4868 - val_accuracy: 0.7700\n",
            "Epoch 302/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4752 - accuracy: 0.7917 - val_loss: 0.4864 - val_accuracy: 0.7700\n",
            "Epoch 303/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4676 - accuracy: 0.7932 - val_loss: 0.4860 - val_accuracy: 0.7700\n",
            "Epoch 304/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4709 - accuracy: 0.8020 - val_loss: 0.4856 - val_accuracy: 0.7700\n",
            "Epoch 305/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4773 - accuracy: 0.8023 - val_loss: 0.4853 - val_accuracy: 0.7700\n",
            "Epoch 306/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4762 - accuracy: 0.7987 - val_loss: 0.4849 - val_accuracy: 0.7700\n",
            "Epoch 307/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4849 - accuracy: 0.7861 - val_loss: 0.4845 - val_accuracy: 0.7700\n",
            "Epoch 308/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4755 - accuracy: 0.7915 - val_loss: 0.4841 - val_accuracy: 0.7700\n",
            "Epoch 309/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4663 - accuracy: 0.7732 - val_loss: 0.4837 - val_accuracy: 0.7700\n",
            "Epoch 310/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4794 - accuracy: 0.7448 - val_loss: 0.4834 - val_accuracy: 0.7700\n",
            "Epoch 311/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4775 - accuracy: 0.7432 - val_loss: 0.4830 - val_accuracy: 0.7700\n",
            "Epoch 312/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4716 - accuracy: 0.7539 - val_loss: 0.4826 - val_accuracy: 0.7700\n",
            "Epoch 313/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4676 - accuracy: 0.7539 - val_loss: 0.4823 - val_accuracy: 0.7700\n",
            "Epoch 314/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4720 - accuracy: 0.7544 - val_loss: 0.4819 - val_accuracy: 0.7700\n",
            "Epoch 315/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7682 - val_loss: 0.4815 - val_accuracy: 0.7700\n",
            "Epoch 316/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.7645 - val_loss: 0.4812 - val_accuracy: 0.7700\n",
            "Epoch 317/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4687 - accuracy: 0.7764 - val_loss: 0.4808 - val_accuracy: 0.7700\n",
            "Epoch 318/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4498 - accuracy: 0.7965 - val_loss: 0.4804 - val_accuracy: 0.7650\n",
            "Epoch 319/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4826 - accuracy: 0.7602 - val_loss: 0.4801 - val_accuracy: 0.7700\n",
            "Epoch 320/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.7688 - val_loss: 0.4797 - val_accuracy: 0.7700\n",
            "Epoch 321/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4531 - accuracy: 0.7808 - val_loss: 0.4794 - val_accuracy: 0.7700\n",
            "Epoch 322/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4686 - accuracy: 0.7618 - val_loss: 0.4790 - val_accuracy: 0.7700\n",
            "Epoch 323/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4783 - accuracy: 0.7691 - val_loss: 0.4787 - val_accuracy: 0.7700\n",
            "Epoch 324/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4779 - accuracy: 0.7524 - val_loss: 0.4783 - val_accuracy: 0.7700\n",
            "Epoch 325/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4634 - accuracy: 0.7677 - val_loss: 0.4780 - val_accuracy: 0.7700\n",
            "Epoch 326/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.7855 - val_loss: 0.4776 - val_accuracy: 0.7700\n",
            "Epoch 327/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4684 - accuracy: 0.7857 - val_loss: 0.4773 - val_accuracy: 0.7700\n",
            "Epoch 328/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4707 - accuracy: 0.7730 - val_loss: 0.4769 - val_accuracy: 0.7700\n",
            "Epoch 329/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4677 - accuracy: 0.7919 - val_loss: 0.4766 - val_accuracy: 0.7700\n",
            "Epoch 330/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4724 - accuracy: 0.7920 - val_loss: 0.4762 - val_accuracy: 0.7700\n",
            "Epoch 331/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4725 - accuracy: 0.7790 - val_loss: 0.4759 - val_accuracy: 0.7700\n",
            "Epoch 332/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4636 - accuracy: 0.7906 - val_loss: 0.4756 - val_accuracy: 0.7700\n",
            "Epoch 333/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4648 - accuracy: 0.7895 - val_loss: 0.4752 - val_accuracy: 0.7700\n",
            "Epoch 334/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.8061 - val_loss: 0.4749 - val_accuracy: 0.7700\n",
            "Epoch 335/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.8048 - val_loss: 0.4746 - val_accuracy: 0.7700\n",
            "Epoch 336/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4546 - accuracy: 0.7978 - val_loss: 0.4742 - val_accuracy: 0.7700\n",
            "Epoch 337/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4500 - accuracy: 0.7999 - val_loss: 0.4739 - val_accuracy: 0.7700\n",
            "Epoch 338/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4669 - accuracy: 0.7944 - val_loss: 0.4736 - val_accuracy: 0.7700\n",
            "Epoch 339/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.7901 - val_loss: 0.4732 - val_accuracy: 0.7700\n",
            "Epoch 340/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.8006 - val_loss: 0.4729 - val_accuracy: 0.7700\n",
            "Epoch 341/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4537 - accuracy: 0.8013 - val_loss: 0.4726 - val_accuracy: 0.7700\n",
            "Epoch 342/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4580 - accuracy: 0.8094 - val_loss: 0.4723 - val_accuracy: 0.7700\n",
            "Epoch 343/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.8090 - val_loss: 0.4719 - val_accuracy: 0.7700\n",
            "Epoch 344/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.8051 - val_loss: 0.4716 - val_accuracy: 0.7700\n",
            "Epoch 345/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4733 - accuracy: 0.7918 - val_loss: 0.4713 - val_accuracy: 0.7700\n",
            "Epoch 346/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4631 - accuracy: 0.7874 - val_loss: 0.4710 - val_accuracy: 0.7700\n",
            "Epoch 347/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4528 - accuracy: 0.7771 - val_loss: 0.4706 - val_accuracy: 0.7700\n",
            "Epoch 348/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4668 - accuracy: 0.7476 - val_loss: 0.4703 - val_accuracy: 0.7700\n",
            "Epoch 349/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4652 - accuracy: 0.7501 - val_loss: 0.4700 - val_accuracy: 0.7700\n",
            "Epoch 350/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7617 - val_loss: 0.4697 - val_accuracy: 0.7700\n",
            "Epoch 351/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4563 - accuracy: 0.7608 - val_loss: 0.4694 - val_accuracy: 0.7700\n",
            "Epoch 352/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7670 - val_loss: 0.4691 - val_accuracy: 0.7700\n",
            "Epoch 353/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.7787 - val_loss: 0.4688 - val_accuracy: 0.7700\n",
            "Epoch 354/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.7738 - val_loss: 0.4685 - val_accuracy: 0.7700\n",
            "Epoch 355/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4559 - accuracy: 0.7847 - val_loss: 0.4681 - val_accuracy: 0.7700\n",
            "Epoch 356/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.8005 - val_loss: 0.4678 - val_accuracy: 0.7700\n",
            "Epoch 357/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4714 - accuracy: 0.7639 - val_loss: 0.4675 - val_accuracy: 0.7700\n",
            "Epoch 358/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.7731 - val_loss: 0.4672 - val_accuracy: 0.7700\n",
            "Epoch 359/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7848 - val_loss: 0.4669 - val_accuracy: 0.7700\n",
            "Epoch 360/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.7655 - val_loss: 0.4666 - val_accuracy: 0.7700\n",
            "Epoch 361/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4675 - accuracy: 0.7724 - val_loss: 0.4663 - val_accuracy: 0.7700\n",
            "Epoch 362/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4684 - accuracy: 0.7555 - val_loss: 0.4660 - val_accuracy: 0.7700\n",
            "Epoch 363/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4531 - accuracy: 0.7705 - val_loss: 0.4657 - val_accuracy: 0.7700\n",
            "Epoch 364/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4498 - accuracy: 0.7880 - val_loss: 0.4654 - val_accuracy: 0.7700\n",
            "Epoch 365/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4569 - accuracy: 0.7880 - val_loss: 0.4651 - val_accuracy: 0.7700\n",
            "Epoch 366/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7751 - val_loss: 0.4648 - val_accuracy: 0.7700\n",
            "Epoch 367/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.7937 - val_loss: 0.4645 - val_accuracy: 0.7700\n",
            "Epoch 368/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7935 - val_loss: 0.4642 - val_accuracy: 0.7700\n",
            "Epoch 369/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4612 - accuracy: 0.7873 - val_loss: 0.4639 - val_accuracy: 0.7700\n",
            "Epoch 370/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4523 - accuracy: 0.7971 - val_loss: 0.4636 - val_accuracy: 0.7700\n",
            "Epoch 371/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4530 - accuracy: 0.7903 - val_loss: 0.4633 - val_accuracy: 0.7700\n",
            "Epoch 372/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.8068 - val_loss: 0.4630 - val_accuracy: 0.7700\n",
            "Epoch 373/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.8054 - val_loss: 0.4628 - val_accuracy: 0.7700\n",
            "Epoch 374/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4433 - accuracy: 0.7982 - val_loss: 0.4625 - val_accuracy: 0.7700\n",
            "Epoch 375/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4382 - accuracy: 0.8142 - val_loss: 0.4622 - val_accuracy: 0.7700\n",
            "Epoch 376/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4560 - accuracy: 0.8059 - val_loss: 0.4619 - val_accuracy: 0.7700\n",
            "Epoch 377/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.8000 - val_loss: 0.4616 - val_accuracy: 0.7700\n",
            "Epoch 378/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4490 - accuracy: 0.8093 - val_loss: 0.4613 - val_accuracy: 0.7700\n",
            "Epoch 379/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.8092 - val_loss: 0.4610 - val_accuracy: 0.7700\n",
            "Epoch 380/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4471 - accuracy: 0.8104 - val_loss: 0.4608 - val_accuracy: 0.7750\n",
            "Epoch 381/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4529 - accuracy: 0.8109 - val_loss: 0.4605 - val_accuracy: 0.7750\n",
            "Epoch 382/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4526 - accuracy: 0.8069 - val_loss: 0.4602 - val_accuracy: 0.7750\n",
            "Epoch 383/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4634 - accuracy: 0.7862 - val_loss: 0.4599 - val_accuracy: 0.7750\n",
            "Epoch 384/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4525 - accuracy: 0.7929 - val_loss: 0.4597 - val_accuracy: 0.7750\n",
            "Epoch 385/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7910 - val_loss: 0.4594 - val_accuracy: 0.7750\n",
            "Epoch 386/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4562 - accuracy: 0.7592 - val_loss: 0.4591 - val_accuracy: 0.7750\n",
            "Epoch 387/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4547 - accuracy: 0.7628 - val_loss: 0.4588 - val_accuracy: 0.7700\n",
            "Epoch 388/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4487 - accuracy: 0.7706 - val_loss: 0.4586 - val_accuracy: 0.7700\n",
            "Epoch 389/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4467 - accuracy: 0.7711 - val_loss: 0.4583 - val_accuracy: 0.7700\n",
            "Epoch 390/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4506 - accuracy: 0.7764 - val_loss: 0.4580 - val_accuracy: 0.7700\n",
            "Epoch 391/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.7875 - val_loss: 0.4577 - val_accuracy: 0.7700\n",
            "Epoch 392/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4331 - accuracy: 0.7847 - val_loss: 0.4575 - val_accuracy: 0.7650\n",
            "Epoch 393/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.7947 - val_loss: 0.4572 - val_accuracy: 0.7650\n",
            "Epoch 394/500\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 0.4265 - accuracy: 0.8097 - val_loss: 0.4569 - val_accuracy: 0.7650\n",
            "Epoch 395/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4619 - accuracy: 0.7723 - val_loss: 0.4567 - val_accuracy: 0.7650\n",
            "Epoch 396/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.7868 - val_loss: 0.4564 - val_accuracy: 0.7650\n",
            "Epoch 397/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4297 - accuracy: 0.8034 - val_loss: 0.4561 - val_accuracy: 0.7650\n",
            "Epoch 398/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4476 - accuracy: 0.7811 - val_loss: 0.4559 - val_accuracy: 0.7650\n",
            "Epoch 399/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4582 - accuracy: 0.7862 - val_loss: 0.4556 - val_accuracy: 0.7650\n",
            "Epoch 400/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4604 - accuracy: 0.7679 - val_loss: 0.4553 - val_accuracy: 0.7650\n",
            "Epoch 401/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.7817 - val_loss: 0.4551 - val_accuracy: 0.7650\n",
            "Epoch 402/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.7983 - val_loss: 0.4548 - val_accuracy: 0.7650\n",
            "Epoch 403/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.7974 - val_loss: 0.4546 - val_accuracy: 0.7650\n",
            "Epoch 404/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4498 - accuracy: 0.7836 - val_loss: 0.4543 - val_accuracy: 0.7650\n",
            "Epoch 405/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.8016 - val_loss: 0.4541 - val_accuracy: 0.7650\n",
            "Epoch 406/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4498 - accuracy: 0.8016 - val_loss: 0.4538 - val_accuracy: 0.7650\n",
            "Epoch 407/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4514 - accuracy: 0.7947 - val_loss: 0.4535 - val_accuracy: 0.7650\n",
            "Epoch 408/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4426 - accuracy: 0.8038 - val_loss: 0.4533 - val_accuracy: 0.7650\n",
            "Epoch 409/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.8034 - val_loss: 0.4531 - val_accuracy: 0.7650\n",
            "Epoch 410/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.8177 - val_loss: 0.4528 - val_accuracy: 0.7650\n",
            "Epoch 411/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4306 - accuracy: 0.8149 - val_loss: 0.4525 - val_accuracy: 0.7650\n",
            "Epoch 412/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.8137 - val_loss: 0.4523 - val_accuracy: 0.7650\n",
            "Epoch 413/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8273 - val_loss: 0.4520 - val_accuracy: 0.7650\n",
            "Epoch 414/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4465 - accuracy: 0.8177 - val_loss: 0.4518 - val_accuracy: 0.7650\n",
            "Epoch 415/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4443 - accuracy: 0.8105 - val_loss: 0.4515 - val_accuracy: 0.7650\n",
            "Epoch 416/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4386 - accuracy: 0.8258 - val_loss: 0.4513 - val_accuracy: 0.7650\n",
            "Epoch 417/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.8232 - val_loss: 0.4510 - val_accuracy: 0.7650\n",
            "Epoch 418/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.8219 - val_loss: 0.4508 - val_accuracy: 0.7650\n",
            "Epoch 419/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.8282 - val_loss: 0.4506 - val_accuracy: 0.7650\n",
            "Epoch 420/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.8226 - val_loss: 0.4503 - val_accuracy: 0.7650\n",
            "Epoch 421/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4550 - accuracy: 0.7998 - val_loss: 0.4501 - val_accuracy: 0.7650\n",
            "Epoch 422/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.8124 - val_loss: 0.4498 - val_accuracy: 0.7650\n",
            "Epoch 423/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.8060 - val_loss: 0.4496 - val_accuracy: 0.7650\n",
            "Epoch 424/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4472 - accuracy: 0.7725 - val_loss: 0.4494 - val_accuracy: 0.7650\n",
            "Epoch 425/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7748 - val_loss: 0.4491 - val_accuracy: 0.7650\n",
            "Epoch 426/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.7814 - val_loss: 0.4489 - val_accuracy: 0.7650\n",
            "Epoch 427/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.7785 - val_loss: 0.4486 - val_accuracy: 0.7650\n",
            "Epoch 428/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4422 - accuracy: 0.7831 - val_loss: 0.4484 - val_accuracy: 0.7650\n",
            "Epoch 429/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4282 - accuracy: 0.7934 - val_loss: 0.4482 - val_accuracy: 0.7650\n",
            "Epoch 430/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.7942 - val_loss: 0.4479 - val_accuracy: 0.7650\n",
            "Epoch 431/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.8025 - val_loss: 0.4477 - val_accuracy: 0.7650\n",
            "Epoch 432/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4171 - accuracy: 0.8178 - val_loss: 0.4475 - val_accuracy: 0.7650\n",
            "Epoch 433/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4537 - accuracy: 0.7796 - val_loss: 0.4472 - val_accuracy: 0.7650\n",
            "Epoch 434/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4322 - accuracy: 0.7935 - val_loss: 0.4470 - val_accuracy: 0.7650\n",
            "Epoch 435/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.8095 - val_loss: 0.4468 - val_accuracy: 0.7650\n",
            "Epoch 436/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.7867 - val_loss: 0.4465 - val_accuracy: 0.7650\n",
            "Epoch 437/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4501 - accuracy: 0.7914 - val_loss: 0.4463 - val_accuracy: 0.7650\n",
            "Epoch 438/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4534 - accuracy: 0.7727 - val_loss: 0.4461 - val_accuracy: 0.7650\n",
            "Epoch 439/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4364 - accuracy: 0.7862 - val_loss: 0.4458 - val_accuracy: 0.7650\n",
            "Epoch 440/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.8024 - val_loss: 0.4456 - val_accuracy: 0.7650\n",
            "Epoch 441/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.8015 - val_loss: 0.4454 - val_accuracy: 0.7650\n",
            "Epoch 442/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.7874 - val_loss: 0.4452 - val_accuracy: 0.7650\n",
            "Epoch 443/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.8050 - val_loss: 0.4449 - val_accuracy: 0.7650\n",
            "Epoch 444/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.8038 - val_loss: 0.4447 - val_accuracy: 0.7650\n",
            "Epoch 445/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.7967 - val_loss: 0.4445 - val_accuracy: 0.7700\n",
            "Epoch 446/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.8126 - val_loss: 0.4443 - val_accuracy: 0.7700\n",
            "Epoch 447/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4340 - accuracy: 0.8104 - val_loss: 0.4440 - val_accuracy: 0.7700\n",
            "Epoch 448/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4211 - accuracy: 0.8237 - val_loss: 0.4438 - val_accuracy: 0.7700\n",
            "Epoch 449/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4223 - accuracy: 0.8221 - val_loss: 0.4436 - val_accuracy: 0.7700\n",
            "Epoch 450/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4250 - accuracy: 0.8202 - val_loss: 0.4434 - val_accuracy: 0.7700\n",
            "Epoch 451/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4190 - accuracy: 0.8332 - val_loss: 0.4432 - val_accuracy: 0.7700\n",
            "Epoch 452/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.8223 - val_loss: 0.4429 - val_accuracy: 0.7700\n",
            "Epoch 453/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.8146 - val_loss: 0.4427 - val_accuracy: 0.7700\n",
            "Epoch 454/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.8366 - val_loss: 0.4425 - val_accuracy: 0.7700\n",
            "Epoch 455/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4228 - accuracy: 0.8320 - val_loss: 0.4423 - val_accuracy: 0.7700\n",
            "Epoch 456/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4293 - accuracy: 0.8285 - val_loss: 0.4421 - val_accuracy: 0.7700\n",
            "Epoch 457/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.8341 - val_loss: 0.4419 - val_accuracy: 0.7700\n",
            "Epoch 458/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4349 - accuracy: 0.8282 - val_loss: 0.4416 - val_accuracy: 0.7700\n",
            "Epoch 459/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4477 - accuracy: 0.8049 - val_loss: 0.4414 - val_accuracy: 0.7700\n",
            "Epoch 460/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4357 - accuracy: 0.8171 - val_loss: 0.4412 - val_accuracy: 0.7700\n",
            "Epoch 461/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4232 - accuracy: 0.8104 - val_loss: 0.4410 - val_accuracy: 0.7700\n",
            "Epoch 462/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.7765 - val_loss: 0.4408 - val_accuracy: 0.7700\n",
            "Epoch 463/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.7785 - val_loss: 0.4406 - val_accuracy: 0.7700\n",
            "Epoch 464/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.7849 - val_loss: 0.4404 - val_accuracy: 0.7700\n",
            "Epoch 465/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.7817 - val_loss: 0.4402 - val_accuracy: 0.7700\n",
            "Epoch 466/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.7897 - val_loss: 0.4400 - val_accuracy: 0.7700\n",
            "Epoch 467/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.7994 - val_loss: 0.4397 - val_accuracy: 0.7750\n",
            "Epoch 468/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4156 - accuracy: 0.7997 - val_loss: 0.4395 - val_accuracy: 0.7750\n",
            "Epoch 469/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4274 - accuracy: 0.8076 - val_loss: 0.4393 - val_accuracy: 0.7750\n",
            "Epoch 470/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4089 - accuracy: 0.8226 - val_loss: 0.4391 - val_accuracy: 0.7750\n",
            "Epoch 471/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.7841 - val_loss: 0.4389 - val_accuracy: 0.7700\n",
            "Epoch 472/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.7976 - val_loss: 0.4387 - val_accuracy: 0.7700\n",
            "Epoch 473/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4122 - accuracy: 0.8135 - val_loss: 0.4385 - val_accuracy: 0.7700\n",
            "Epoch 474/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.7904 - val_loss: 0.4383 - val_accuracy: 0.7700\n",
            "Epoch 475/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.7947 - val_loss: 0.4381 - val_accuracy: 0.7700\n",
            "Epoch 476/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.7757 - val_loss: 0.4379 - val_accuracy: 0.7700\n",
            "Epoch 477/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.7959 - val_loss: 0.4377 - val_accuracy: 0.7700\n",
            "Epoch 478/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.8103 - val_loss: 0.4375 - val_accuracy: 0.7700\n",
            "Epoch 479/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4309 - accuracy: 0.8080 - val_loss: 0.4373 - val_accuracy: 0.7700\n",
            "Epoch 480/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4339 - accuracy: 0.7932 - val_loss: 0.4371 - val_accuracy: 0.7700\n",
            "Epoch 481/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.8103 - val_loss: 0.4369 - val_accuracy: 0.7700\n",
            "Epoch 482/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.8069 - val_loss: 0.4367 - val_accuracy: 0.7700\n",
            "Epoch 483/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.7995 - val_loss: 0.4365 - val_accuracy: 0.7700\n",
            "Epoch 484/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4268 - accuracy: 0.8151 - val_loss: 0.4363 - val_accuracy: 0.7700\n",
            "Epoch 485/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.8127 - val_loss: 0.4361 - val_accuracy: 0.7700\n",
            "Epoch 486/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4128 - accuracy: 0.8258 - val_loss: 0.4359 - val_accuracy: 0.7700\n",
            "Epoch 487/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4149 - accuracy: 0.8221 - val_loss: 0.4357 - val_accuracy: 0.7700\n",
            "Epoch 488/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4174 - accuracy: 0.8202 - val_loss: 0.4355 - val_accuracy: 0.7750\n",
            "Epoch 489/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4111 - accuracy: 0.8331 - val_loss: 0.4353 - val_accuracy: 0.7750\n",
            "Epoch 490/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.8234 - val_loss: 0.4351 - val_accuracy: 0.7750\n",
            "Epoch 491/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4286 - accuracy: 0.8156 - val_loss: 0.4349 - val_accuracy: 0.7750\n",
            "Epoch 492/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.8374 - val_loss: 0.4347 - val_accuracy: 0.7750\n",
            "Epoch 493/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4150 - accuracy: 0.8400 - val_loss: 0.4345 - val_accuracy: 0.7750\n",
            "Epoch 494/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.8359 - val_loss: 0.4344 - val_accuracy: 0.7750\n",
            "Epoch 495/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4274 - accuracy: 0.8404 - val_loss: 0.4342 - val_accuracy: 0.7750\n",
            "Epoch 496/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8340 - val_loss: 0.4340 - val_accuracy: 0.7750\n",
            "Epoch 497/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4413 - accuracy: 0.8101 - val_loss: 0.4338 - val_accuracy: 0.7750\n",
            "Epoch 498/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.8217 - val_loss: 0.4336 - val_accuracy: 0.7750\n",
            "Epoch 499/500\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 0.4158 - accuracy: 0.8217 - val_loss: 0.4334 - val_accuracy: 0.7750\n",
            "Epoch 500/500\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.7929 - val_loss: 0.4332 - val_accuracy: 0.7750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6Y2tfknjXwN",
        "outputId": "74d28df5-f9d1-4f76-d787-fb3a057bf999"
      },
      "source": [
        "loss, accuracy = model.evaluate(X_train,y_train,verbose=1)\r\n",
        "print(accuracy)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19/19 [==============================] - 0s 1ms/step - loss: 0.4236 - accuracy: 0.8117\n",
            "0.8116666674613953\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zXPc82Mkl8S",
        "outputId": "8ee7d5a9-a796-4c27-df0c-e1fa55d2c225"
      },
      "source": [
        "loss, accuracy = model.evaluate(X_valid,y_valid,verbose=1)\r\n",
        "print(accuracy)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7/7 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7750\n",
            "0.7749999761581421\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6XSRFenloZ5",
        "outputId": "c2988739-52b6-4798-bc1f-fc773fb94b14"
      },
      "source": [
        "loss, accuracy = model.evaluate(X_test,y_test,verbose=1)\r\n",
        "print(accuracy)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7/7 [==============================] - 0s 3ms/step - loss: 0.4249 - accuracy: 0.8300\n",
            "0.8299999833106995\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}